{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "relevant-democracy",
   "metadata": {},
   "source": [
    "## 1. Inference few samples to view ranking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "rapid-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model import KGEModel\n",
    "\n",
    "from dataloader import TrainDataset\n",
    "from dataloader import BidirectionalOneShotIterator\n",
    "\n",
    "CKPT_PATH = \"../models/RotatE_Wiki15k_0\"\n",
    "with open(os.path.join(CKPT_PATH, 'config.json'), 'r') as fjson:\n",
    "    configs = json.load(fjson)\n",
    "class Args():\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "args = Args(**configs)\n",
    "\n",
    "    \n",
    "GPU_DEVICE=0\n",
    "DATA_PATH = \"../data/Wiki15k/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "numerical-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    \n",
    "    def read_triple(file_path, entity2id, relation2id):\n",
    "        triples = []\n",
    "        with open(file_path) as fin:\n",
    "            for line in fin:\n",
    "                h, r, t = line.strip().split('\\t')\n",
    "                triples.append((entity2id[h], relation2id[r], entity2id[t]))\n",
    "        return triples\n",
    "\n",
    "    with open(os.path.join(data_path, 'entities.dict')) as fin:\n",
    "        entity2id = dict()\n",
    "        for line in fin:\n",
    "            eid, entity = line.strip().split('\\t')\n",
    "            entity2id[entity] = int(eid)\n",
    "\n",
    "    with open(os.path.join(data_path, 'relations.dict')) as fin:\n",
    "        relation2id = dict()\n",
    "        for line in fin:\n",
    "            rid, relation = line.strip().split('\\t')\n",
    "            relation2id[relation] = int(rid)\n",
    "            \n",
    "    train_triples = read_triple(os.path.join(data_path, 'train.txt'), entity2id, relation2id)\n",
    "    print('#train: %d' % len(train_triples))\n",
    "    valid_triples = read_triple(os.path.join(data_path, 'valid.txt'), entity2id, relation2id)\n",
    "    print('#valid: %d' % len(valid_triples))\n",
    "    test_triples = read_triple(os.path.join(data_path, 'test.txt'), entity2id, relation2id)\n",
    "    print('#test: %d' % len(test_triples))\n",
    "    all_true_triples = train_triples + valid_triples + test_triples\n",
    "            \n",
    "    infer_triples = read_triple(os.path.join(data_path, 'infer.txt'), entity2id, relation2id)\n",
    "    print('#infer: %d' % len(infer_triples))\n",
    "    \n",
    "    return infer_triples, all_true_triples, entity2id, relation2id\n",
    "\n",
    "# _ = load_data(\"../data/Wiki15k/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "friendly-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(ckpt_path, model_name, nent, nrel, hdim, gamma, de=True, dr=False, use_cuda=True):\n",
    "    \n",
    "    kge_model = KGEModel(\n",
    "        model_name=model_name,\n",
    "        nentity=nent,\n",
    "        nrelation=nrel,\n",
    "        hidden_dim=hdim,\n",
    "        gamma=gamma,\n",
    "        double_entity_embedding=de,\n",
    "        double_relation_embedding=dr\n",
    "    )\n",
    "    \n",
    "    print('Model Parameter Configuration:')\n",
    "    for name, param in kge_model.named_parameters():\n",
    "        print('Parameter %s: %s, require_grad = %s' % (name, str(param.size()), str(param.requires_grad)))\n",
    "\n",
    "    device = torch.device(\"cuda\",GPU_DEVICE) if use_cuda else torch.device(\"cpu\")\n",
    "    kge_model.to(device)\n",
    "    \n",
    "    # Restore model from checkpoint directory\n",
    "    print('Loading checkpoint %s...' % ckpt_path)\n",
    "    checkpoint = torch.load(os.path.join(ckpt_path, 'checkpoint'))\n",
    "    kge_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    return kge_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "following-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(infer_triples, all_true_triples, model, id2ent, id2rel, args, save_path=\"results/\"):\n",
    "    # save ranking results\n",
    "    save_rt = []\n",
    "    save_f = os.path.join(save_path, \"ranking_results.json\")\n",
    "    \n",
    "    metrics, ranking_rt = model.test_step(model, infer_triples, all_true_triples, args)\n",
    "    for metric in metrics:\n",
    "        print('%s %s %f' % (\"test\", metric, metrics[metric]))\n",
    "    # get ranking results\n",
    "    for item in ranking_rt:\n",
    "        p_h, p_r, p_t = id2ent[item[\"positive_sample\"][0]], id2rel[item[\"positive_sample\"][1]], id2ent[item[\"positive_sample\"][2]]\n",
    "        topk_rank_ents = [id2ent[eid] for eid in item[\"topk_rank_idxs\"]]\n",
    "        save_rt.append(\n",
    "            {\"mode\": item[\"mode\"],\n",
    "            \"positive_triple\": [p_h, p_r, p_t],\n",
    "            \"topk_rank_ents\": topk_rank_ents,\n",
    "            \"topk_rank_scores\": item[\"topk_rank_scores\"]\n",
    "            }\n",
    "        )\n",
    "    with open(save_f, \"w\") as f:\n",
    "        json.dump(save_rt, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "introductory-nylon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train: 159036\n",
      "#valid: 8727\n",
      "#test: 8761\n",
      "#infer: 1000\n",
      "Model Parameter Configuration:\n",
      "Parameter gamma: torch.Size([1]), require_grad = False\n",
      "Parameter embedding_range: torch.Size([1]), require_grad = False\n",
      "Parameter entity_embedding: torch.Size([15817, 2000]), require_grad = True\n",
      "Parameter relation_embedding: torch.Size([182, 1000]), require_grad = True\n",
      "Loading checkpoint ../models/RotatE_Wiki15k_0...\n",
      "test MRR 0.408852\n",
      "test MR 364.835000\n",
      "test HITS@1 0.328500\n",
      "test HITS@3 0.453500\n",
      "test HITS@10 0.555000\n"
     ]
    }
   ],
   "source": [
    "# run\n",
    "# load dataset\n",
    "infer_triples, all_true_triples, entity2id, relation2id = load_data(DATA_PATH)\n",
    "id2ent = {v:k for k,v in entity2id.items()}\n",
    "id2rel = {v:k for k,v in relation2id.items()}\n",
    "# load model\n",
    "kge_model = load_model(CKPT_PATH, args.model, len(entity2id), len(relation2id), args.hidden_dim, args.gamma, args.double_entity_embedding, args.double_relation_embedding, use_cuda=True)\n",
    "# inference\n",
    "inference(infer_triples, all_true_triples, kge_model, id2ent, id2rel, args, save_path=\"../results/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-recipient",
   "metadata": {},
   "source": [
    "## 2. Test trained embeddings with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "wooden-reduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15817, 2000)\n",
      "(182, 1000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "ent_embed_file = \"../models/RotatE_Wiki15k_0/entity_embedding.npy\"\n",
    "rel_embed_file = \"../models/RotatE_Wiki15k_0/relation_embedding.npy\"\n",
    "\n",
    "ent_embeddings = np.load(ent_embed_file)\n",
    "rel_embeddings = np.load(rel_embed_file)\n",
    "print(ent_embeddings.shape)\n",
    "print(rel_embeddings.shape)\n",
    "\n",
    "data_path = \"../data/Wiki15k/\"\n",
    "with open(os.path.join(data_path, 'entities.dict')) as fin:\n",
    "        entity2id = dict()\n",
    "        for line in fin:\n",
    "            eid, entity = line.strip().split('\\t')\n",
    "            entity2id[entity] = int(eid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ancient-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_topk_sim_ents(cur_ent, ent2id, ent_embeddings, topk=10, exclude_self=True):\n",
    "    \n",
    "    cur_ent_id = ent2id[cur_ent]\n",
    "    cur_embeddings = [ent_embeddings[cur_ent_id]] * len(ent_embeddings)\n",
    "    \n",
    "    # get scores\n",
    "    coss = np.multiply(cur_embeddings, ent_embeddings).sum(-1) / \\\n",
    "            np.multiply(np.linalg.norm(cur_embeddings, axis=1), np.linalg.norm(ent_embeddings, axis=1))\n",
    "    # sort\n",
    "    argsorts = np.argsort(coss)[::-1]\n",
    "    \n",
    "    topk_idxs = []\n",
    "    topk_ents = []\n",
    "    for i in range(len(argsorts)):\n",
    "        if exclude_self and argsorts[i] != cur_ent_id:\n",
    "            continue\n",
    "        topk_idxs.append(argsorts[i])\n",
    "        for k,v in ent2id.items():\n",
    "            if v == argsorts[i]:\n",
    "                topk_ents.append(k)\n",
    "                break\n",
    "        if len(topk_idxs) == topk:\n",
    "            break\n",
    "    return topk_idxs, topk_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "chronic-falls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q107008', 'Q49575', 'Q1768', 'Q281034', 'Q4030', 'Q229430', 'Q107432', 'Q354508', 'Q82222', 'Q109053', 'Q104358']\n",
      "['Q1701293', 'Q1494959', 'Q1705192', 'Q539757', 'Q7344802', 'Q3021483', 'Q7816353', 'Q7535711', 'Q1767860', 'Q5300549', 'Q2130828']\n",
      "['Q2702789', 'Q2060840', 'Q1584317', 'Q511731', 'Q1321379', 'Q186941', 'Q1404450', 'Q2450848', 'Q168383', 'Q512858', 'Q192557']\n"
     ]
    }
   ],
   "source": [
    "# specify ent for testing\n",
    "test_ents = [\"Q107008\", \"Q1701293\", \"Q2702789\"]\n",
    "for cur_ent in test_ents:\n",
    "    topk_idxs, topk_ents = find_topk_sim_ents(cur_ent, entity2id, ent_embeddings, 11, exclude_self=False)\n",
    "    print(topk_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-server",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
